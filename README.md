# CODTECH-INTERN-Task-1(Linear Regression on Housing Prices)


**NAME**: B CHANGSANG

**ID**: CTO4ML2167

**COMPANY**: CODTECH IT SOLUTIONS

**DOMAIN**: MACHINE LEARNING

**DURATION**: 15th JUNE 20224 TO 15th JULY 2024

**MENTOR**: SRAVANI GOUNI




# PROJECT OVERVIEW

##  INTRODUCTION

Machine Learning's Regression analysis is a foundational statistical method used to model the relationship between a dependent variable and independent variables. When applied to housing prices, regression helps to understand how various factors influence the price of homes. This technique is particularly valuable in real estate for predicting property values, assessing market trends, and making informed investment decisions.

## PREPROCESSING

Data preprocessing is an important analytical process that enhances data quality, resolves discrepancies and ensures that data is correct , consistent and reliable. It establishes a solid basis for meaningful examination. Initially it takes the raw data and process it for analysis. The preprocessing steps are as follows:

- **Polynomial Features:** The dataset is split into training and testing for evaluation. The polynomial features transform the original features into higher dimensional space by adding polynomial terms. This allows a linear model to capture non-linear relationship between the features and the target variables.
- **StandardScaler:** StandardScaler standardizes features by removing the mean and scaling to unit variance. This ensures that each feature contributes equally to the model and that the scale of the features does not adversely affect the performance of the model.
  
## APPLIED METHODS
- **Linear Regression**: Linear regression is an algorithm that provides a linear relationship between an independent variable and a dependent variable to predict the outcome of future events.
- **Ridge Regression**: Ridge regression is a linear regression technique used in statistics and machine learning to address the problem of multicollinearity, which occurs when independent variables in a regression model are highly correlated**: It is a regularization technique that adds a penalty term to the linear regression cost function to prevent the model from becoming too complex and overfitting the data.
-  **Random Forest Regressor**: Random Forest Regression is a versatile machine-learning technique for predicting numerical values. It combines the predictions of multiple decision trees to reduce overfitting.
-  **Decision Tree Regressor**: Decision tree builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes

  
## EVALUATION
The model is evaluated by using Mean Squared Error (MSE) to measure the average squared difference between actual and predicted values,and the R-squared (RÂ²) score to determine the proportion of variance in the target variable explained by the features.

